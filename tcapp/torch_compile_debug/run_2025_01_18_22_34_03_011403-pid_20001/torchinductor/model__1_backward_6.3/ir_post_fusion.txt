op0_op1: OuterLoopFusedSchedulerNode(SchedulerNode,SchedulerNode)
op0_op1.writes = 
    [   MemoryDep('buf0', c0, {c0: s0}, None),
        MemoryDep('buf1', c0, {c0: 10*s0}, None)]
op0_op1.unmet_dependencies = []
op0_op1.met_dependencies = 
    [   MemoryDep('sub_18', c0, {c0: 10*s0}, None),
        MemoryDep('tangents_1', c0, {c0: 10*s0}, None)]
op0_op1.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cpu', torch.float32, size=[s0, 1], stride=[1, s0])
    buf0.users = [NodeUser(node=SchedulerNode(name='op1'), can_inplace=False, is_weak=False)]
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
    buf1.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op2'), can_inplace=False, is_weak=False),
        NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op4'), can_inplace=False, is_weak=False),
    ]
]
op0_op1.snodes[0] =
op0: SchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', c0, {c0: s0}, None)]
op0.unmet_dependencies = []
op0.met_dependencies = [MemoryDep('tangents_1', c0, {c0: 10*s0}, None)]
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cpu', torch.float32, size=[s0, 1], stride=[1, s0])
    buf0.users = [NodeUser(node=SchedulerNode(name='op1'), can_inplace=False, is_weak=False)]
]
op0.group.device = cpu
op0.group.iteration = ((s0,), (10,))
op0.sizes = ([s0], [10])
tangents_1_layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
buf0_layout = FixedLayout('cpu', torch.float32, size=[s0, 1], stride=[1, s0])
class op0_loop_body:
    var_ranges = {z0: s0, z1: 10}
    index0 = 10*z0 + z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('tangents_1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf0', get_index_1, reduction)
        return store_reduction
op0_op1.snodes[1] =
op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 10*s0}, None)]
op1.unmet_dependencies = [MemoryDep('buf0', c0, {c0: s0}, None)]
op1.met_dependencies = 
    [   MemoryDep('sub_18', c0, {c0: 10*s0}, None),
        MemoryDep('tangents_1', c0, {c0: 10*s0}, None)]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
    buf1.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op2'), can_inplace=False, is_weak=False),
        NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op4'), can_inplace=False, is_weak=False),
    ]
]
op1.group.device = cpu
op1.group.iteration = ((s0, 10), ())
op1.sizes = ([s0, 10], [])
tangents_1_layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
sub_18_layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
buf0_layout = FixedLayout('cpu', torch.float32, size=[s0, 1], stride=[1, s0])
buf1_layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
class op1_loop_body:
    var_ranges = {z0: s0, z1: 10}
    index0 = 10*z0 + z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('tangents_1', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('sub_18', get_index_1)
        exp = ops.exp(load_1)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('buf0', get_index_2)
        mul = ops.mul(exp, load_2)
        sub = ops.sub(load, mul)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf1', get_index_3, sub, None)
        return store


op2: ExternKernelSchedulerNode(ExternKernelOut)
op2.writes = [StarDep(name='buf2', mode=None)]
op2.unmet_dependencies = [StarDep(name='buf1', mode=None)]
op2.met_dependencies = [StarDep(name='permute_2', mode=None)]
op2.outputs = [
    buf2: ExternKernelOut
    buf2.layout = FixedLayout('cpu', torch.float32, size=[s0, 128], stride=[128, 1])
    buf2.users = [NodeUser(node=SchedulerNode(name='op5'), can_inplace=True, is_weak=False)]
]
op2.node.kernel = extern_kernels.mm


op3: ExternKernelSchedulerNode(ExternKernelOut)
op3.writes = [StarDep(name='buf3', mode=None)]
op3.unmet_dependencies = [StarDep(name='buf1', mode=None)]
op3.met_dependencies = [StarDep(name='mul_34', mode=None)]
op3.outputs = [
    buf3: ExternKernelOut
    buf3.layout = FixedLayout('cpu', torch.float32, size=[10, 128], stride=[128, 1])
    buf3.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op3.node.kernel = extern_kernels.mm


op4: SchedulerNode(ComputedBuffer)
op4.writes = [MemoryDep('buf4', c0, {c0: 10}, None)]
op4.unmet_dependencies = [MemoryDep('buf1', c0 + 10*c1, {c0: 10, c1: s0}, None)]
op4.met_dependencies = []
op4.outputs = [
    buf4: ComputedBuffer
    buf4.layout = FixedLayout('cpu', torch.float32, size=[1, 10], stride=[10, 1])
    buf4.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op4.group.device = cpu
op4.group.iteration = ((10,), (s0,))
op4.sizes = ([10], [s0])
buf1_layout = FixedLayout('cpu', torch.float32, size=[s0, 10], stride=[10, 1])
buf4_layout = FixedLayout('cpu', torch.float32, size=[1, 10], stride=[10, 1])
class op4_loop_body:
    var_ranges = {z0: 10, z1: s0}
    index0 = z0 + 10*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf4', get_index_1, reduction)
        return store_reduction


op5: SchedulerNode(ComputedBuffer)
op5.writes = [MemoryDep('buf5', c0, {c0: 128*s0}, None)]
op5.unmet_dependencies = [MemoryDep('buf2', c0, {c0: 128*s0}, None)]
op5.met_dependencies = 
    [   MemoryDep('gt_1', c0, {c0: 128*s0}, None),
        MemoryDep('le', c0, {c0: 128*s0}, None)]
op5.outputs = [
    buf5: ComputedBuffer
    buf5.layout = FixedLayout('cpu', torch.float32, size=[s0, 128], stride=[128, 1])
    buf5.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op6'), can_inplace=False, is_weak=False),
        NodeUser(node=ExternKernelSchedulerNode(name='op7'), can_inplace=False, is_weak=False),
        NodeUser(node=SchedulerNode(name='op8'), can_inplace=False, is_weak=False),
    ]
]
op5.group.device = cpu
op5.group.iteration = ((128*s0,), ())
op5.sizes = ([128*s0], [])
le_layout = FixedLayout('cpu', torch.bool, size=[s0, 128], stride=[128, 1])
buf2_layout = FixedLayout('cpu', torch.float32, size=[s0, 128], stride=[128, 1])
gt_1_layout = FixedLayout('cpu', torch.bool, size=[s0, 128], stride=[128, 1])
buf5_layout = FixedLayout('cpu', torch.float32, size=[s0, 128], stride=[128, 1])
class op5_loop_body:
    var_ranges = {z0: 128*s0}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('le', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf2', get_index_1)
        get_index_2 = self.get_index('index0')
        load_2 = ops.load('gt_1', get_index_2)
        to_dtype = ops.to_dtype(load_2, torch.float32, src_dtype = torch.bool)
        constant = ops.constant(2.0, torch.float32)
        mul = ops.mul(to_dtype, constant)
        mul_1 = ops.mul(load_1, mul)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(load, constant_1, mul_1)
        get_index_3 = self.get_index('index0')
        store = ops.store('buf5', get_index_3, where, None)
        return store


op6: ExternKernelSchedulerNode(ExternKernelOut)
op6.writes = [StarDep(name='buf6', mode=None)]
op6.unmet_dependencies = [StarDep(name='buf5', mode=None)]
op6.met_dependencies = [StarDep(name='permute_6', mode=None)]
op6.outputs = [
    buf6: ExternKernelOut
    buf6.layout = FixedLayout('cpu', torch.float32, size=[s0, 9216], stride=[9216, 1])
    buf6.users = [NodeUser(node=SchedulerNode(name='op9'), can_inplace=True, is_weak=False)]
]
op6.node.kernel = extern_kernels.mm


op7: ExternKernelSchedulerNode(ExternKernelOut)
op7.writes = [StarDep(name='buf7', mode=None)]
op7.unmet_dependencies = [StarDep(name='buf5', mode=None)]
op7.met_dependencies = [StarDep(name='view', mode=None)]
op7.outputs = [
    buf7: ExternKernelOut
    buf7.layout = FixedLayout('cpu', torch.float32, size=[128, 9216], stride=[9216, 1])
    buf7.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op7.node.kernel = extern_kernels.mm


op8: SchedulerNode(ComputedBuffer)
op8.writes = [MemoryDep('buf8', c0, {c0: 128}, None)]
op8.unmet_dependencies = [MemoryDep('buf5', c0 + 128*c1, {c0: 128, c1: s0}, None)]
op8.met_dependencies = []
op8.outputs = [
    buf8: ComputedBuffer
    buf8.layout = FixedLayout('cpu', torch.float32, size=[1, 128], stride=[128, 1])
    buf8.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op8.group.device = cpu
op8.group.iteration = ((128,), (s0,))
op8.sizes = ([128], [s0])
buf5_layout = FixedLayout('cpu', torch.float32, size=[s0, 128], stride=[128, 1])
buf8_layout = FixedLayout('cpu', torch.float32, size=[1, 128], stride=[128, 1])
class op8_loop_body:
    var_ranges = {z0: 128, z1: s0}
    index0 = z0 + 128*z1
    index1 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf5', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf8', get_index_1, reduction)
        return store_reduction


op9: SchedulerNode(ComputedBuffer)
op9.writes = [MemoryDep('buf9', c0, {c0: 9216*s0}, None)]
op9.unmet_dependencies = [MemoryDep('buf6', c0, {c0: 9216*s0}, None)]
op9.met_dependencies = [MemoryDep('gt', c0, {c0: 9216*s0}, None)]
op9.outputs = [
    buf9: ComputedBuffer
    buf9.layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 12, 12], stride=[9216, 144, 12, 1])
    buf9.users = [NodeUser(node=SchedulerNode(name='op10'), can_inplace=False, is_weak=False)]
]
op9.group.device = cpu
op9.group.iteration = ((9216*s0,), ())
op9.sizes = ([9216*s0], [])
buf6_layout = FixedLayout('cpu', torch.float32, size=[s0, 9216], stride=[9216, 1])
gt_layout = FixedLayout('cpu', torch.bool, size=[s0, 64, 12, 12], stride=[9216, 144, 12, 1])
buf9_layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 12, 12], stride=[9216, 144, 12, 1])
class op9_loop_body:
    var_ranges = {z0: 9216*s0}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf6', get_index)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('gt', get_index_1)
        to_dtype = ops.to_dtype(load_1, torch.float32, src_dtype = torch.bool)
        constant = ops.constant(1.3333333333333333, torch.float32)
        mul = ops.mul(to_dtype, constant)
        mul_1 = ops.mul(load, mul)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf9', get_index_2, mul_1, None)
        return store


op10_op11: FusedSchedulerNode(SchedulerNode,SchedulerNode)
op10_op11.writes = 
    [   MemoryDep('buf10', c0, {c0: 36864*s0}, None),
        MemoryDep('buf11', c0, {c0: 36864*s0}, None)]
op10_op11.unmet_dependencies = [   MemoryDep('buf9', 9216*c0 + 144*c3 + 12*Min(Min(12, (c1//2) + 1) - 1, Max(0, (c1//2))) + Min(Min(12, (c2//2) + 1) - 1, Max(0, (c2//2))), {c0: s0, c1: 24, c2: 24, c3: 64}, None)]
op10_op11.met_dependencies = 
    [   MemoryDep('getitem_1', 9216*c0 + c3 + 768*Min(Min(12, (c1//2) + 1) - 1, Max(0, (c1//2))) + 64*Min(Min(12, (c2//2) + 1) - 1, Max(0, (c2//2))), {c0: s0, c1: 24, c2: 24, c3: 64}, None),
        MemoryDep('relu_1', c0, {c0: 36864*s0}, None)]
op10_op11.outputs = [
    buf10: ComputedBuffer
    buf10.layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
    buf10.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=True, is_weak=False)]
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
    buf11.users = [NodeUser(node=ExternKernelSchedulerNode(name='op12'), can_inplace=False, is_weak=False)]
]
op10_op11.snodes[0] =
op10: SchedulerNode(ComputedBuffer)
op10.writes = [MemoryDep('buf10', c0, {c0: 36864*s0}, None)]
op10.unmet_dependencies = [   MemoryDep('buf9', 9216*c0 + 144*c3 + 12*Min(Min(12, (c1//2) + 1) - 1, Max(0, (c1//2))) + Min(Min(12, (c2//2) + 1) - 1, Max(0, (c2//2))), {c0: s0, c1: 24, c2: 24, c3: 64}, None)]
op10.met_dependencies = [   MemoryDep('getitem_1', 9216*c0 + c3 + 768*Min(Min(12, (c1//2) + 1) - 1, Max(0, (c1//2))) + 64*Min(Min(12, (c2//2) + 1) - 1, Max(0, (c2//2))), {c0: s0, c1: 24, c2: 24, c3: 64}, None)]
op10.outputs = [
    buf10: ComputedBuffer
    buf10.layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
    buf10.users = [NodeUser(node=SchedulerNode(name='op11'), can_inplace=True, is_weak=False)]
]
op10.group.device = cpu
op10.group.iteration = ((s0, 24, 24, 64), ())
op10.sizes = ([s0, 24, 24, 64], [])
getitem_1_layout = FixedLayout('cpu', torch.int8, size=[s0, 64, 12, 12], stride=[9216, 1, 768, 64])
buf9_layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 12, 12], stride=[9216, 144, 12, 1])
buf10_layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
class op10_loop_body:
    var_ranges = {z0: s0, z1: 24, z2: 24, z3: 64}
    index0 = 9216*z0 + z3 + 768*Min(Min(12, (z1//2) + 1) - 1, Max(0, (z1//2))) + 64*Min(Min(12, (z2//2) + 1) - 1, Max(0, (z2//2)))
    index1 = 2*Min(Min(12, (z1//2) + 1) - 1, Max(0, (z1//2)))
    index2 = 2*Min(Min(12, (z2//2) + 1) - 1, Max(0, (z2//2)))
    index3 = 9216*z0 + 144*z3 + 12*Min(Min(12, (z1//2) + 1) - 1, Max(0, (z1//2))) + Min(Min(12, (z2//2) + 1) - 1, Max(0, (z2//2)))
    index4 = 24*z1 + z2
    index5 = 36864*z0 + 1536*z1 + 64*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('getitem_1', get_index)
        constant = ops.constant(2, torch.int32)
        floordiv = ops.floordiv(load, constant)
        constant_1 = ops.constant(2, torch.int32)
        mul = ops.mul(floordiv, constant_1)
        sub = ops.sub(load, mul)
        get_index_1 = self.get_index('index1')
        index_expr = ops.index_expr(get_index_1, torch.int64)
        add = ops.add(index_expr, floordiv)
        get_index_2 = self.get_index('index2')
        index_expr_1 = ops.index_expr(get_index_2, torch.int64)
        add_1 = ops.add(index_expr_1, sub)
        constant_2 = ops.constant(24, torch.int64)
        mul_1 = ops.mul(add, constant_2)
        add_2 = ops.add(mul_1, add_1)
        get_index_3 = self.get_index('index3')
        load_1 = ops.load('buf9', get_index_3)
        get_index_4 = self.get_index('index4')
        index_expr_2 = ops.index_expr(get_index_4, torch.int32)
        eq = ops.eq(add_2, index_expr_2)
        constant_3 = ops.constant(0.0, torch.float32)
        where = ops.where(eq, load_1, constant_3)
        get_index_5 = self.get_index('index5')
        store = ops.store('buf10', get_index_5, where, None)
        return store
op10_op11.snodes[1] =
op11: SchedulerNode(ComputedBuffer)
op11.writes = [MemoryDep('buf11', c0, {c0: 36864*s0}, None)]
op11.unmet_dependencies = [MemoryDep('buf10', c0, {c0: 36864*s0}, None)]
op11.met_dependencies = [MemoryDep('relu_1', c0, {c0: 36864*s0}, None)]
op11.outputs = [
    buf11: ComputedBuffer
    buf11.layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
    buf11.users = [NodeUser(node=ExternKernelSchedulerNode(name='op12'), can_inplace=False, is_weak=False)]
]
op11.group.device = cpu
op11.group.iteration = ((s0, 24, 24, 64), ())
op11.sizes = ([s0, 24, 24, 64], [])
relu_1_layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
buf10_layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
buf11_layout = FixedLayout('cpu', torch.float32, size=[s0, 64, 24, 24], stride=[36864, 1, 1536, 64])
class op11_loop_body:
    var_ranges = {z0: s0, z1: 24, z2: 24, z3: 64}
    index0 = 36864*z0 + 1536*z1 + 64*z2 + z3
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu_1', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf10', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf11', get_index_2, where, None)
        return store


op12: ExternKernelSchedulerNode(FallbackKernel)
op12.writes = [StarDep(name='buf12', mode=None)]
op12.unmet_dependencies = [StarDep(name='buf11', mode=None)]
op12.met_dependencies = [StarDep(name='primals_5', mode=None), StarDep(name='relu', mode=None)]
op12.outputs = [
    buf12: FallbackKernel
    buf12.layout = MultiOutputLayout(device=device(type='cpu'))
    buf12.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op13'), can_inplace=False, is_weak=False),
        NodeUser(node=ExternKernelSchedulerNode(name='op14'), can_inplace=False, is_weak=False),
        NodeUser(node=ExternKernelSchedulerNode(name='op15'), can_inplace=False, is_weak=False),
    ]
]
op12.node.kernel = torch.ops.aten.convolution_backward.default


op13: ExternKernelSchedulerNode(MultiOutput)
op13.writes = [StarDep(name='buf13', mode=None)]
op13.unmet_dependencies = [StarDep(name='buf12', mode=None)]
op13.met_dependencies = []
op13.outputs = [
    buf13: MultiOutput
    buf13.layout = FixedLayout('cpu', torch.float32, size=[s0, 32, 26, 26], stride=[21632, 1, 832, 32])
    buf13.users = [NodeUser(node=SchedulerNode(name='op16'), can_inplace=True, is_weak=False)]
]
op13.node.kernel = None


op14: ExternKernelSchedulerNode(MultiOutput)
op14.writes = [StarDep(name='buf14', mode=None)]
op14.unmet_dependencies = [StarDep(name='buf12', mode=None)]
op14.met_dependencies = []
op14.outputs = [
    buf14: MultiOutput
    buf14.layout = FixedLayout('cpu', torch.float32, size=[64, 32, 3, 3], stride=[288, 1, 96, 32])
    buf14.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op14.node.kernel = None


op15: ExternKernelSchedulerNode(MultiOutput)
op15.writes = [StarDep(name='buf15', mode=None)]
op15.unmet_dependencies = [StarDep(name='buf12', mode=None)]
op15.met_dependencies = []
op15.outputs = [
    buf15: MultiOutput
    buf15.layout = FixedLayout('cpu', torch.float32, size=[64], stride=[1])
    buf15.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op15.node.kernel = None


op16: SchedulerNode(ComputedBuffer)
op16.writes = [MemoryDep('buf16', c0, {c0: 21632*s0}, None)]
op16.unmet_dependencies = [MemoryDep('buf13', c0, {c0: 21632*s0}, None)]
op16.met_dependencies = [MemoryDep('relu', c0, {c0: 21632*s0}, None)]
op16.outputs = [
    buf16: ComputedBuffer
    buf16.layout = FixedLayout('cpu', torch.float32, size=[s0, 32, 26, 26], stride=[21632, 1, 832, 32])
    buf16.users = [NodeUser(node=ExternKernelSchedulerNode(name='op17'), can_inplace=False, is_weak=False)]
]
op16.group.device = cpu
op16.group.iteration = ((21632*s0,), ())
op16.sizes = ([21632*s0], [])
relu_layout = FixedLayout('cpu', torch.float32, size=[s0, 32, 26, 26], stride=[21632, 1, 832, 32])
buf13_layout = FixedLayout('cpu', torch.float32, size=[s0, 32, 26, 26], stride=[21632, 1, 832, 32])
buf16_layout = FixedLayout('cpu', torch.float32, size=[s0, 32, 26, 26], stride=[21632, 1, 832, 32])
class op16_loop_body:
    var_ranges = {z0: 21632*s0}
    index0 = z0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('relu', get_index)
        constant = ops.constant(0.0, torch.float32)
        le = ops.le(load, constant)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('buf13', get_index_1)
        constant_1 = ops.constant(0.0, torch.float32)
        where = ops.where(le, constant_1, load_1)
        get_index_2 = self.get_index('index0')
        store = ops.store('buf16', get_index_2, where, None)
        return store


op17: ExternKernelSchedulerNode(FallbackKernel)
op17.writes = [StarDep(name='buf17', mode=None)]
op17.unmet_dependencies = [StarDep(name='buf16', mode=None)]
op17.met_dependencies = [StarDep(name='primals_1', mode=None), StarDep(name='primals_4', mode=None)]
op17.outputs = [
    buf17: FallbackKernel
    buf17.layout = MultiOutputLayout(device=device(type='cpu'))
    buf17.users = [
        NodeUser(node=ExternKernelSchedulerNode(name='op18'), can_inplace=False, is_weak=False),
        NodeUser(node=ExternKernelSchedulerNode(name='op19'), can_inplace=False, is_weak=False),
    ]
]
op17.node.kernel = torch.ops.aten.convolution_backward.default


op18: ExternKernelSchedulerNode(MultiOutput)
op18.writes = [StarDep(name='buf18', mode=None)]
op18.unmet_dependencies = [StarDep(name='buf17', mode=None)]
op18.met_dependencies = []
op18.outputs = [
    buf18: MultiOutput
    buf18.layout = FixedLayout('cpu', torch.float32, size=[32, 1, 3, 3], stride=[9, 9, 3, 1])
    buf18.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op18.node.kernel = None


op19: ExternKernelSchedulerNode(MultiOutput)
op19.writes = [StarDep(name='buf19', mode=None)]
op19.unmet_dependencies = [StarDep(name='buf17', mode=None)]
op19.met_dependencies = []
op19.outputs = [
    buf19: MultiOutput
    buf19.layout = FixedLayout('cpu', torch.float32, size=[32], stride=[1])
    buf19.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op19.node.kernel = None


